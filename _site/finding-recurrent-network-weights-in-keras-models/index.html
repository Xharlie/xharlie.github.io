<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Finding Recurrent Weights in Keras Models &#8211; </title>
<meta name="description" content="As a researcher who is trying to gain a better understanding of the internal dynamics of recurrent neural networks, sometimes I want to look at the trained weights of my networks.
To train my networks, I use the library Keras.
In general I am very happy with this library, as it allows me to easily change the architecture of my network, try different layer types and use different optimizers.
Inspecting the weights of Keras networks, however, is not the easiest task, nor is printing the activation of its hidden layers (on which more later).

">
<meta name="keywords" content="">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Finding Recurrent Weights in Keras Models">
<meta name="twitter:description" content="As a researcher who is trying to gain a better understanding of the internal dynamics of recurrent neural networks, sometimes I want to look at the trained weights of my networks.
To train my networks, I use the library Keras.
In general I am very happy with this library, as it allows me to easily change the architecture of my network, try different layer types and use different optimizers.
Inspecting the weights of Keras networks, however, is not the easiest task, nor is printing the activation of its hidden layers (on which more later).

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="/images/default-thumb.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Finding Recurrent Weights in Keras Models">
<meta property="og:description" content="As a researcher who is trying to gain a better understanding of the internal dynamics of recurrent neural networks, sometimes I want to look at the trained weights of my networks.
To train my networks, I use the library Keras.
In general I am very happy with this library, as it allows me to easily change the architecture of my network, try different layer types and use different optimizers.
Inspecting the weights of Keras networks, however, is not the easiest task, nor is printing the activation of its hidden layers (on which more later).

">
<meta property="og:url" content="/finding-recurrent-network-weights-in-keras-models/">
<meta property="og:site_name" content="">





<link rel="canonical" href="/finding-recurrent-network-weights-in-keras-models/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="/assets/js/vendor/html5shiv.min.js"></script>
	<script src="/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="/"></a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="/"/"/" >About</a></li>
				
				    
				    <li><a href="/projects/" >Projects</a></li>
				
				    
				    <li><a href="/publications/" >Publications</a></li>
				
				    
				    <li><a href="/teaching/" >Teaching</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->




<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="/images/avatar_large.jpeg" class="bio-photo" alt="Qiangeng(Charlie) Xu bio photo">


  <h3 itemprop="name">Qiangeng(Charlie) Xu</h3>
  <p></p>
  <a href="mailto:qiangenx@usc.edu" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a>
  
  <a href="https://www.linkedin.com/in/qiangeng-charlie-xu-6789b857" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a>
  
  <a href="http://instagram.com/youlikecharlieorwhat" class="author-social" target="_blank"><i class="fa fa-fw fa-instagram"></i> Instagram</a>
  
  <a href="http://github.com/xharlie" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  

  <!-- Mailing address -->
  <br><h4>Mailing address</h4> Powell Hall, Room 108 <br> University of Southern California <br> 3737 Watt Way, Los Angeles, U.S. <br> zip code: 90089

</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        <h1><a href="/finding-recurrent-network-weights-in-keras-models/" rel="bookmark" title="Finding Recurrent Weights in Keras Models">Finding Recurrent Weights in Keras Models</a></h1>
      
    </div><!--/ .headline-wrap -->
    <div class="article-wrap">
      <p>As a researcher who is trying to gain a better understanding of the internal dynamics of recurrent neural networks, sometimes I want to look at the trained weights of my networks.
To train my networks, I use the library <a href="keras.io" target="_blank">Keras</a>.
In general I am very happy with this library, as it allows me to easily change the architecture of my network, try different layer types and use different optimizers.
Inspecting the weights of Keras networks, however, is not the easiest task, nor is printing the activation of its hidden layers (on which more later).</p>

<p>Although all layersâ€™ weights can be accessed via a function <code class="highlighter-rouge">get_weights()</code>, for recurrent layers this function returns a  list of arrays storing concatenations of gate, and hidden layer weights (and biases), of which the order is not mentioned.
After a little digging in the source code I found that in the latest release of Keras (which is Keras2 at this moment) the different weight matrices are stored in attributes of the layer.
As I feel that accessing and the weight matrices of networks should be easy (and common practice), I decided to share this with you in my first blog post.</p>

<h3 id="finding-weights-of-a-gru-layer">Finding weights of a GRU layer</h3>

<p>Thus, following the example on the Keras website, we create a network with one GRU layer:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">GRU</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span></code></pre></figure>

<p>Now, the last (and only) layer of this network is a GRU layer, whose different weight matrices we can access as follows.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">GRU_layer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">recurrent_weights</span> <span class="o">=</span> <span class="n">GRU_layer</span><span class="o">.</span><span class="n">recurrent_kernel_h</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">update_gate_weights</span> <span class="o">=</span> <span class="n">GRU_layer</span><span class="o">.</span><span class="n">recurrent_kernel_r</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">reset_gate_weights</span> <span class="o">=</span> <span class="n">GRU_layer</span><span class="o">.</span><span class="n">recurrent_kernel_z</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span></code></pre></figure>

<p>The bias and weights from the input to the hidden layer, update- and reset gate are stored in <code class="highlighter-rouge">layer.bias_\{h,r,z\}</code> and <code class="highlighter-rouge">kernel_\{h,r,z\}</code>, respectively.</p>

<h3 id="so-what-does-the-get_weights-method-return">So, what does the <code class="highlighter-rouge">get_weights()</code> method return?</h3>

<p>Now that we have the values of the different weight matrices, we can find out in which order the weights are concatenated in the output of the  <code class="highlighter-rouge">get_weights()</code> method.
After running a bunch of statements of the form</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">GRU_layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">1</span><span class="p">][:,</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">],</span> <span class="n">recurrent_weights</span><span class="p">)</span></code></pre></figure>

<p>I conclude that for the <code class="highlighter-rouge">get_weights()</code> function returns</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">GRU</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span> <span class="o">=</span> <span class="p">[[</span><span class="n">W_z</span><span class="p">;</span> <span class="n">W_r</span><span class="p">;</span> <span class="n">W_h</span><span class="p">],</span> <span class="p">[</span><span class="n">U_z</span><span class="p">;</span> <span class="n">U_r</span><span class="p">;</span> <span class="n">U_h</span><span class="p">],</span> <span class="p">[</span><span class="n">bias_z</span><span class="p">;</span> <span class="n">bias_r</span><span class="p">;</span> <span class="n">bias_h</span><span class="p">]]</span></code></pre></figure>

<p>Well, that was it for now, hope this was useful for anyone (and if not, it will probably be for future me :)).</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
<!--  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=/finding-recurrent-network-weights-in-keras-models/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=/finding-recurrent-network-weights-in-keras-models/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=/finding-recurrent-network-weights-in-keras-models/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul> -->
</div><!-- /.social-share -->

        <p class="byline"><strong>Finding Recurrent Weights in Keras Models</strong> was published on <time datetime="2017-05-21T00:00:00-07:00">May 21, 2017</time>.</p>
      </footer>
    </div><!-- /.article-wrap -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <footer>
    

<span>&copy; 2018 Qiangeng(Charlie) Xu. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>


  
	        


<div id="disqus_thread"></div>
<script>
/* * * Configuration variables * * */
var discus_config function () {
    this.page.url = "http://dieuwkehupkes.nl/finding-recurrent-network-weights-in-keras-models/";
    this.page.identifier = "/finding-recurrent-network-weights-in-keras-models";
};
(function() {
    var d = document, s = d.createElement('script');

    s.src = '//dieuwke.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>




</body>
</html>
